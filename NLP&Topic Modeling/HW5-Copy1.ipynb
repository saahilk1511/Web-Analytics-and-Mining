{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb33c012",
   "metadata": {},
   "source": [
    "## 1. From the Indiegogo (https://webrobots.io/indiegogo-dataset/) dataset you need to download at least 5 JSON (or CSV) files. Use the content of “tagline” or “title” from downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "420663bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c237c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2021 = pd.read_json(\"Indiegogo_2021-09-17T20_40_51_080Z.json\",lines=True)\n",
    "year_2020 = pd.read_json(\"Indiegogo_2020-11-13T10_41_00_593Z.json\",lines=True)\n",
    "year_2019 = pd.read_json(\"Indiegogo_2019-11-15T10_40_02_728Z.json\",lines=True)\n",
    "year_2018 = pd.read_json(\"Indiegogo_2018-11-16T10_40_36_940Z.json\",lines=True)\n",
    "year_2017 = pd.read_json(\"Indiegogo_2017-11-15T10_40_47_201Z.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365b281e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scroll Down - Contribute to Research! Mold in Mattress? Outdoor Stachybotrys? DNA (ERMI) Inhibition?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_2021[\"data\"][0][\"tagline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1114c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mold Research Continues'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_2021[\"data\"][0][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e42471",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "tagline = []\n",
    "for i in range(0, 1000):\n",
    "    title.append(year_2021[\"data\"][i][\"title\"])\n",
    "    tagline.append(year_2021[\"data\"][i][\"tagline\"])\n",
    "    \n",
    "    title.append(year_2020[\"data\"][i][\"title\"])\n",
    "    tagline.append(year_2020[\"data\"][i][\"tagline\"])\n",
    "    \n",
    "    title.append(year_2019[\"data\"][i][\"title\"])\n",
    "    tagline.append(year_2019[\"data\"][i][\"tagline\"])\n",
    "    \n",
    "    title.append(year_2018[\"data\"][i][\"title\"])\n",
    "    tagline.append(year_2018[\"data\"][i][\"tagline\"])\n",
    "    \n",
    "    title.append(year_2017[\"data\"][i][\"title\"])\n",
    "    tagline.append(year_2017[\"data\"][i][\"tagline\"])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ce0374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>taglines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mold Research Continues</td>\n",
       "      <td>Scroll Down - Contribute to Research! Mold in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Scoutmother</td>\n",
       "      <td>Female-driven mob boss movie parody in the sty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geography Club - The Television Series</td>\n",
       "      <td>A television drama series based on the 2013 fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abba.. Zappa Seventies Rock Photography: The App</td>\n",
       "      <td>We have the book, now we need your help to pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liquid Death Spring Water</td>\n",
       "      <td>Murder your thirst.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>The Cleveland Candle Company</td>\n",
       "      <td>Help us bring a fresh new experience to Clevel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Gogo-S: Wireless &amp; Waterproof Sports Earbuds</td>\n",
       "      <td>Truewireless earbuds with music play, dynamic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Camp WannaTippaTrashCan Book Series</td>\n",
       "      <td>A middle-readers series about the marauding mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>SACRED</td>\n",
       "      <td>connecting people with God through music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Night light-Most interest magnetic levitation ...</td>\n",
       "      <td>Redefining noctilucent lights and enjoying the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 titles  \\\n",
       "0                               Mold Research Continues   \n",
       "1                                       The Scoutmother   \n",
       "2                Geography Club - The Television Series   \n",
       "3      Abba.. Zappa Seventies Rock Photography: The App   \n",
       "4                             Liquid Death Spring Water   \n",
       "...                                                 ...   \n",
       "4995                       The Cleveland Candle Company   \n",
       "4996       Gogo-S: Wireless & Waterproof Sports Earbuds   \n",
       "4997                Camp WannaTippaTrashCan Book Series   \n",
       "4998                                             SACRED   \n",
       "4999  Night light-Most interest magnetic levitation ...   \n",
       "\n",
       "                                               taglines  \n",
       "0     Scroll Down - Contribute to Research! Mold in ...  \n",
       "1     Female-driven mob boss movie parody in the sty...  \n",
       "2     A television drama series based on the 2013 fe...  \n",
       "3     We have the book, now we need your help to pro...  \n",
       "4                                   Murder your thirst.  \n",
       "...                                                 ...  \n",
       "4995  Help us bring a fresh new experience to Clevel...  \n",
       "4996  Truewireless earbuds with music play, dynamic ...  \n",
       "4997  A middle-readers series about the marauding mi...  \n",
       "4998           connecting people with God through music  \n",
       "4999  Redefining noctilucent lights and enjoying the...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(title, tagline)),columns =['titles', 'taglines'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ece117a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75a0373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db4fd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_clean\"] = df['titles'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97afde86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ec27b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4589\n"
     ]
    }
   ],
   "source": [
    "# Might take awhile...\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(df[\"title_clean\"])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38f27f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abba', 'Zappa', 'Seventies', 'Rock', 'Photography', 'App']\n"
     ]
    }
   ],
   "source": [
    "message = df[\"title_clean\"]\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c6de417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2624)\t1\n",
      "  (1, 3459)\t1\n",
      "  (2, 1513)\t1\n",
      "  (3, 105)\t1\n",
      "  (4, 2347)\t1\n",
      "  (5, 570)\t1\n",
      "  (6, 1321)\t1\n",
      "  (7, 275)\t1\n",
      "  (8, 1019)\t1\n",
      "  (9, 2981)\t1\n",
      "  (10, 3731)\t1\n",
      "  (11, 1424)\t1\n",
      "  (12, 4282)\t1\n",
      "  (13, 674)\t1\n",
      "  (14, 77)\t1\n",
      "  (15, 1002)\t1\n",
      "  (16, 1381)\t1\n",
      "  (17, 3454)\t1\n",
      "  (18, 3848)\t1\n",
      "  (19, 280)\t1\n",
      "  (20, 1506)\t1\n",
      "  (21, 3193)\t1\n",
      "  (22, 2732)\t1\n",
      "  (23, 921)\t1\n",
      "  (24, 3998)\t1\n",
      "  :\t:\n",
      "  (4975, 1392)\t1\n",
      "  (4976, 4151)\t1\n",
      "  (4977, 764)\t1\n",
      "  (4978, 3711)\t1\n",
      "  (4979, 61)\t1\n",
      "  (4980, 72)\t1\n",
      "  (4981, 3578)\t1\n",
      "  (4982, 1902)\t1\n",
      "  (4983, 2163)\t1\n",
      "  (4984, 2459)\t1\n",
      "  (4985, 3918)\t1\n",
      "  (4986, 4477)\t1\n",
      "  (4987, 760)\t1\n",
      "  (4988, 1082)\t1\n",
      "  (4989, 2069)\t1\n",
      "  (4990, 4014)\t1\n",
      "  (4991, 426)\t1\n",
      "  (4992, 2858)\t1\n",
      "  (4993, 1618)\t1\n",
      "  (4994, 2908)\t1\n",
      "  (4995, 782)\t1\n",
      "  (4996, 1565)\t1\n",
      "  (4997, 646)\t1\n",
      "  (4998, 3328)\t1\n",
      "  (4999, 2784)\t1\n",
      "(5000, 4589)\n"
     ]
    }
   ],
   "source": [
    "bow = bow_transformer.transform(df[\"title_clean\"])\n",
    "print(bow)\n",
    "print(bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a188d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2624)\t1.0\n",
      "  (1, 3459)\t1.0\n",
      "  (2, 1513)\t1.0\n",
      "  (3, 105)\t1.0\n",
      "  (4, 2347)\t1.0\n",
      "  (5, 570)\t1.0\n",
      "  (6, 1321)\t1.0\n",
      "  (7, 275)\t1.0\n",
      "  (8, 1019)\t1.0\n",
      "  (9, 2981)\t1.0\n",
      "  (10, 3731)\t1.0\n",
      "  (11, 1424)\t1.0\n",
      "  (12, 4282)\t1.0\n",
      "  (13, 674)\t1.0\n",
      "  (14, 77)\t1.0\n",
      "  (15, 1002)\t1.0\n",
      "  (16, 1381)\t1.0\n",
      "  (17, 3454)\t1.0\n",
      "  (18, 3848)\t1.0\n",
      "  (19, 280)\t1.0\n",
      "  (20, 1506)\t1.0\n",
      "  (21, 3193)\t1.0\n",
      "  (22, 2732)\t1.0\n",
      "  (23, 921)\t1.0\n",
      "  (24, 3998)\t1.0\n",
      "  :\t:\n",
      "  (4975, 1392)\t1.0\n",
      "  (4976, 4151)\t1.0\n",
      "  (4977, 764)\t1.0\n",
      "  (4978, 3711)\t1.0\n",
      "  (4979, 61)\t1.0\n",
      "  (4980, 72)\t1.0\n",
      "  (4981, 3578)\t1.0\n",
      "  (4982, 1902)\t1.0\n",
      "  (4983, 2163)\t1.0\n",
      "  (4984, 2459)\t1.0\n",
      "  (4985, 3918)\t1.0\n",
      "  (4986, 4477)\t1.0\n",
      "  (4987, 760)\t1.0\n",
      "  (4988, 1082)\t1.0\n",
      "  (4989, 2069)\t1.0\n",
      "  (4990, 4014)\t1.0\n",
      "  (4991, 426)\t1.0\n",
      "  (4992, 2858)\t1.0\n",
      "  (4993, 1618)\t1.0\n",
      "  (4994, 2908)\t1.0\n",
      "  (4995, 782)\t1.0\n",
      "  (4996, 1565)\t1.0\n",
      "  (4997, 646)\t1.0\n",
      "  (4998, 3328)\t1.0\n",
      "  (4999, 2784)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "messages_bow = bow_transformer.transform(df[\"title_clean\"])\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe6da8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfTransformer()\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99872522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tfd)",
   "language": "python",
   "name": "tfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
